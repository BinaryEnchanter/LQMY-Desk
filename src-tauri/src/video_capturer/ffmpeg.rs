use ac_ffmpeg::codec::Encoder;
use std::collections::HashMap;
use std::str::FromStr;
use std::sync::atomic::{AtomicBool, AtomicU64, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{broadcast, RwLock};
use winapi::shared::ws2ipdef::IN6_PKTINFO;

use ac_ffmpeg::codec::video::frame::{PixelFormat, VideoFrame, VideoFrameMut};
//use ac_ffmpeg::codec::video::{VideoEncoder, VideoFrameMut};
use ac_ffmpeg::time::{TimeBase, Timestamp};
use ac_ffmpeg::Error;
use rusty_duplication::{FrameInfoExt, Scanner, VecCapturer};
use webrtc::track::track_local::track_local_static_sample::TrackLocalStaticSample;

use ac_ffmpeg::codec::video::scaler::{Algorithm, VideoFrameScaler, VideoFrameScalerBuilder};

/// å°† RawFrameï¼ˆBGRAï¼‰è½¬æ¢ä¸ºç›®æ ‡å®½é«˜ã€YUV420P åƒç´ æ ¼å¼çš„ VideoFrame
pub fn bgra_to_yuv420p_frame(
    raw_frame: &RawFrame,
    params: &EncodingParams,
    time_base: TimeBase,
    frame_idx: i64,
) -> Result<VideoFrame, Error> {
    // 1. å‡†å¤‡è¾“å…¥ VideoFrameMutï¼šæ ¼å¼ BGRAã€å°ºå¯¸ä¸º raw_frame.width Ã— raw_frame.height
    let input_fmt = PixelFormat::from_str("bgra")
        .map_err(|_| Error::new("Unknown input pixel format 'bgra'".to_string()))?;
    //   .ok_or_else(|| Error::new("Unknown input pixel format 'bgra'".to_string()))?;
    let src_w = raw_frame.width as usize;
    let src_h = raw_frame.height as usize;

    // åˆ†é…ä¸€ä¸ªé»‘è‰² BGRA å¸§ï¼Œç”¨æ¥æ‹·è´åŸå§‹æ•°æ®
    let mut input_video_frame =
        VideoFrameMut::black(input_fmt, src_w, src_h).with_time_base(time_base);

    {
        // ä»…æœ‰ä¸€ä¸ªå¹³é¢ï¼Œæ‰“åŒ…æ ¼å¼ BGRAï¼Œå°† raw_frame.data é€è¡Œæ‹·è´åˆ° planes_mut()[0]

        let mut planes = input_video_frame.planes_mut();
        let line_size = planes[0].line_size() as usize;
        let plane_data = planes[0].data_mut();
        let bytes_per_line = raw_frame.width as usize * 4; // BGRA æ¯åƒç´  4 å­—èŠ‚

        for y in 0..src_h {
            let src_offset = y * bytes_per_line;
            let dst_offset = y * line_size;
            // é˜²æ­¢è¶Šç•Œ
            if src_offset + bytes_per_line <= raw_frame.data.len()
                && dst_offset + bytes_per_line <= plane_data.len()
            {
                plane_data[dst_offset..dst_offset + bytes_per_line]
                    .copy_from_slice(&raw_frame.data[src_offset..src_offset + bytes_per_line]);
            }
        }
    }
    // å†»ç»“è¾“å…¥å¸§å¹¶è®¾ç½® PTS
    let pts = Timestamp::new(frame_idx, time_base);
    let input_frozen: VideoFrame = input_video_frame.freeze().with_pts(pts);

    // 2. è®¡ç®—ç›®æ ‡å®½é«˜ï¼ˆYUV420P è¦æ±‚å¶æ•°å¯¹é½ï¼‰
    let dst_w = if params.width % 2 == 0 {
        params.width
    } else {
        params.width - 1
    };
    let dst_h = if params.height % 2 == 0 {
        params.height
    } else {
        params.height - 1
    };

    // 3. æ„å»º VideoFrameScalerï¼ˆæ³¨æ„ç”¨ VideoFrameScaler::builder()ï¼‰
    let output_fmt = PixelFormat::from_str("yuv420p")
        .map_err(|_| Error::new("Unknown input pixel format 'bgra'".to_string()))?;
    //    .ok_or_else(|| Error::new("Unknown output pixel format 'yuv420p'".to_string()))?;
    let mut scaler: VideoFrameScaler = VideoFrameScaler::builder()
        .source_pixel_format(input_fmt)
        .source_width(src_w)
        .source_height(src_h)
        .target_pixel_format(output_fmt)
        .target_width(dst_w as usize)
        .target_height(dst_h as usize)
        // å¦‚æœéœ€è¦æŒ‡å®šç®—æ³•ï¼Œå¯ä»¥åŠ ä¸Š `.algorithm(Algorithm::Bilinear)` ç­‰ï¼Œé»˜è®¤æ˜¯ Bicubic
        .algorithm(Algorithm::Bicubic)
        .build()?;

    // 4. æ‰§è¡Œç¼©æ”¾ä¸åƒç´ æ ¼å¼è½¬æ¢ï¼šBGRA â†’ YUV420P
    let mut scaled_frame = scaler.scale(&input_frozen)?;

    // 5. è®¾ç½®æ­£ç¡®çš„ PTSï¼ˆscale åçš„å¸§å¯èƒ½ä¿ç•™äº†è¾“å…¥ PTSï¼Œä½†ä¸ºäº†ä¿é™©ï¼Œè¿™é‡Œé‡ç½®ä¸€æ¬¡ï¼‰
    scaled_frame = scaled_frame.with_pts(Timestamp::new(frame_idx, time_base));

    Ok(scaled_frame)
}

#[derive(Clone)]
pub struct RawFrame {
    pub width: u32,
    pub height: u32,
    pub data: Arc<Vec<u8>>, // BGRAæ ¼å¼
    pub timestamp: u64,
    pub frame_id: u64,
}

#[derive(Clone)]
pub struct EncodingParams {
    pub width: u32,
    pub height: u32,
    pub fps: u32,
    pub bitrate: u32,
}

struct EncoderWorker {
    handle: std::thread::JoinHandle<()>, // æ”¹ä¸ºstd::thread::JoinHandle
    shutdown: Arc<AtomicBool>,
}

pub struct MultiStreamManager {
    capture_handle: Option<std::thread::JoinHandle<()>>, // æ”¹ä¸ºstd::thread::JoinHandle
    capture_shutdown: Arc<AtomicBool>,
    frame_broadcast: Option<broadcast::Sender<RawFrame>>,
    encoders: Arc<RwLock<HashMap<String, EncoderWorker>>>,
    frame_counter: Arc<AtomicU64>,
}

impl MultiStreamManager {
    pub fn new() -> Self {
        Self {
            capture_handle: None,
            capture_shutdown: Arc::new(AtomicBool::new(false)),
            frame_broadcast: None,
            encoders: Arc::new(RwLock::new(HashMap::new())),
            frame_counter: Arc::new(AtomicU64::new(0)),
        }
    }

    pub async fn start_capture(&mut self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        if self.capture_handle.is_some() {
            return Ok(());
        }

        // å‡å°ç¼“å†²åŒºåˆ°æœ€å°ï¼Œé¿å…å¸§ç§¯å‹
        let (tx, _) = broadcast::channel::<RawFrame>(2); // ä»100æ”¹ä¸º2
        self.frame_broadcast = Some(tx.clone());
        self.capture_shutdown.store(false, Ordering::Relaxed);
        let shutdown_signal = self.capture_shutdown.clone();
        let frame_counter = self.frame_counter.clone();
        let encoders = self.encoders.clone();

        // ä½¿ç”¨std::thread::spawnåˆ›å»ºç‹¬å çº¿ç¨‹
        let handle = std::thread::spawn(move || {
            // åœ¨ç‹¬å çº¿ç¨‹ä¸­åˆ›å»ºtokioè¿è¡Œæ—¶
            let rt = tokio::runtime::Runtime::new().unwrap();
            rt.block_on(async {
                Self::capture_loop(shutdown_signal, frame_counter, tx, encoders).await;
            });
        });

        self.capture_handle = Some(handle);
        Ok(())
    }

    async fn capture_loop(
        shutdown_signal: Arc<AtomicBool>,
        frame_counter: Arc<AtomicU64>,
        tx: broadcast::Sender<RawFrame>,
        encoders: Arc<RwLock<HashMap<String, EncoderWorker>>>,
    ) {
        let mut scanner = match Scanner::new() {
            Ok(s) => s,
            Err(_) => return,
        };

        let monitor = match scanner.next() {
            Some(m) => m,
            None => return,
        };

        let mut capturer: VecCapturer = match monitor.try_into() {
            Ok(c) => c,
            Err(_) => return,
        };

        let mut last_capture = Instant::now();
        let capture_interval = Duration::from_millis(33); // æ”¹ä¸º30fpsè€Œä¸æ˜¯60fps
        let mut skip_counter = 0;

        while !shutdown_signal.load(Ordering::Relaxed) {
            // æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç¼–ç å™¨åœ¨å·¥ä½œ
            {
                let encoders_guard = encoders.read().await;
                if encoders_guard.is_empty() {
                    tokio::time::sleep(Duration::from_millis(10)).await;
                    continue;
                }
            }

            if let Ok(info) = capturer.capture() {
                if info.desktop_updated() {
                    // åªæœ‰æ»¡è¶³æ—¶é—´é—´éš”æ‰å¤„ç†å¸§
                    if last_capture.elapsed() >= capture_interval {
                        let desc = capturer.monitor().dxgi_outdupl_desc();
                        let frame_id = frame_counter.fetch_add(1, Ordering::Relaxed);

                        let raw_frame = RawFrame {
                            width: desc.ModeDesc.Width,
                            height: desc.ModeDesc.Height,
                            data: Arc::new(capturer.buffer.clone()),
                            timestamp: frame_id,
                            frame_id,
                        };

                        last_capture = Instant::now();

                        // éé˜»å¡å‘é€ï¼Œå¦‚æœé€šé“æ»¡äº†å°±ä¸¢å¼ƒæ—§å¸§
                        match tx.send(raw_frame) {
                            Ok(_) => {}
                            Err(_) => {
                                // é€šé“å·²å…³é—­æˆ–æ»¡äº†ï¼Œè·³è¿‡è¿™å¸§
                                skip_counter += 1;
                                if skip_counter % 30 == 0 {
                                    println!(
                                        "Dropped {} frames due to channel congestion",
                                        skip_counter
                                    );
                                }
                            }
                        }
                    } else {
                        // æœªåˆ°æ—¶é—´é—´éš”ï¼ŒçŸ­æš‚ä¼‘çœ é¿å…CPUå ç”¨è¿‡é«˜
                        tokio::time::sleep(Duration::from_millis(1)).await;
                    }
                }
            }
        }
    }
    pub async fn add_webrtc_track(
        &self,
        client_uuid: &str,
        track: Arc<TrackLocalStaticSample>,
        params: EncodingParams,
    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let frame_rx = match &self.frame_broadcast {
            Some(tx) => tx.subscribe(),
            None => return Err("Capture not started".into()),
        };

        let mut encoders = self.encoders.write().await;

        // å¦‚æœå·²å­˜åœ¨ï¼Œå…ˆå…³é—­æ—§çš„
        if let Some(old_worker) = encoders.remove(client_uuid) {
            old_worker.shutdown.store(true, Ordering::Relaxed);
            // ç­‰å¾…æ—§çº¿ç¨‹ç»“æŸ
            if let Err(e) = old_worker.handle.join() {
                eprintln!("Error waiting for old encoder to finish: {:?}", e);
            }
        }
        println!("Adding new encoder for client: {}", client_uuid);
        let shutdown = Arc::new(AtomicBool::new(false));

        // ä½¿ç”¨std::thread::spawnåˆ›å»ºç‹¬å çº¿ç¨‹
        let handle = std::thread::spawn({
            let shutdown = shutdown.clone();
            move || {
                // åœ¨ç‹¬å çº¿ç¨‹ä¸­åˆ›å»ºtokioè¿è¡Œæ—¶
                let rt = tokio::runtime::Runtime::new().unwrap();
                rt.block_on(async {
                    Self::encoder_worker(frame_rx, track, params, shutdown).await;
                });
            }
        });

        let worker = EncoderWorker { handle, shutdown };

        encoders.insert(client_uuid.to_string(), worker);
        Ok(())
    }

    async fn encoder_worker(
        mut frame_rx: broadcast::Receiver<RawFrame>,
        track: Arc<TrackLocalStaticSample>,
        params: EncodingParams,
        shutdown: Arc<AtomicBool>,
    ) {
        let mut encoder = match Self::create_h264_encoder(&params) {
            Ok(e) => e,
            Err(e) => {
                eprintln!("Failed to create encoder: {}", e);
                return;
            }
        };

        let time_base = TimeBase::new(1, params.fps as i32);
        let mut frame_idx = 0i64;
        let mut frames_processed = 0i64;
        let mut frame_sent = 0i64;
        let mut time = Instant::now();
        let frame_duration = Duration::from_millis(1000 / params.fps as u64);

        while !shutdown.load(Ordering::Relaxed) {
            // å‡å°‘è¶…æ—¶æ—¶é—´ï¼Œæ›´å¿«å“åº”
            match tokio::time::timeout(Duration::from_millis(50), frame_rx.recv()).await {
                Ok(Ok(mut raw_frame)) => {
                    // æ¸…ç©ºæ¥æ”¶ç¼“å†²åŒºï¼Œåªå¤„ç†æœ€æ–°å¸§
                    loop {
                        match frame_rx.try_recv() {
                            Ok(newer_frame) => {
                                // æœ‰æ›´æ–°çš„å¸§ï¼Œä¸¢å¼ƒå½“å‰å¸§
                                raw_frame = newer_frame;
                            }
                            Err(broadcast::error::TryRecvError::Empty) => break,
                            Err(_) => break,
                        }
                    }

                    match bgra_to_yuv420p_frame(&raw_frame, &params, time_base, frame_idx) {
                        Ok(yuv_frame) => {
                            frame_idx += 1;
                            frames_processed += 1;

                            // // æ¯30å¸§æ‰“å°ä¸€æ¬¡çŠ¶æ€ï¼Œç¡®è®¤ç¼–ç å™¨åœ¨å·¥ä½œ
                            // if frames_processed % 30 == 0 {
                            //     println!("Processed {} frames", frames_processed);
                            // }

                            if encoder.try_push(yuv_frame).is_ok() {
                                // ç«‹å³å¤„ç†æ‰€æœ‰å¯ç”¨çš„åŒ…
                                while let Some(packet) = encoder.take().unwrap_or(None) {
                                    let data = packet.data().to_vec();

                                    if let Err(err) = track
                                        .write_sample(&webrtc::media::Sample {
                                            data: data.into(),
                                            duration: frame_duration,
                                            ..Default::default()
                                        })
                                        .await
                                    {
                                        eprintln!("Failed to write sample: {:?}", err);
                                        return;
                                    }
                                }
                                frame_sent += 1;

                                // æ¯30å¸§æ‰“å°ä¸€æ¬¡çŠ¶æ€ï¼Œç¡®è®¤ç¼–ç å™¨åœ¨å·¥ä½œ
                                if Instant::now().duration_since(time) >= Duration::from_secs(1) {
                                    println!(
                                        "Processed {} frames,Send {} frames",
                                        frames_processed, frame_sent
                                    );
                                    frame_sent = 0;
                                    frames_processed = 0;
                                    time = Instant::now();
                                }
                            } else {
                                println!("[]fail to push to encoder")
                            }
                        }
                        Err(err) => {
                            eprintln!("Failed to convert frame to YUV420P: {}", err);
                            continue;
                        }
                    }
                }
                Ok(Err(_)) => continue,
                Err(_) => continue, // è¶…æ—¶ï¼Œç»§ç»­å¾ªç¯
            }
        }

        // åˆ·æ–°ç¼–ç å™¨
        let _ = encoder.try_flush();
        while let Some(packet) = encoder.take().unwrap_or(None) {
            let data = packet.data().to_vec();
            let _ = track
                .write_sample(&webrtc::media::Sample {
                    data: data.into(),
                    duration: frame_duration,
                    ..Default::default()
                })
                .await;
        }
    }

    /// åˆ›å»º H.264 ç¼–ç å™¨ï¼ˆæœŸæœ›è¾“å…¥åƒç´ æ ¼å¼ YUV420Pã€å°ºå¯¸ä¸º params.width Ã— params.heightï¼‰
    /// åˆ›å»º H.264 ç¼–ç å™¨ï¼Œæ”¯æŒGPUåŠ é€Ÿ
    fn create_h264_encoder(
        params: &EncodingParams,
    ) -> Result<ac_ffmpeg::codec::video::VideoEncoder, Error> {
        let time_base = TimeBase::new(1, params.fps as i32);
        let output_pixel_format = PixelFormat::from_str("yuv420p")
            .map_err(|_| Error::new("Unknown pixel format 'yuv420p'".to_string()))?;

        // æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒç¼–ç å™¨
        let encoders = ["libx264", "h264_nvenc", "h264_amf", "h264_qsv"];

        for &encoder_name in &encoders {
            if let Ok(mut builder) = ac_ffmpeg::codec::video::VideoEncoder::builder(encoder_name) {
                println!("Using encoder: {}", encoder_name);

                builder = builder
                    .pixel_format(output_pixel_format)
                    .width(params.width as _)
                    .height(params.height as _)
                    .time_base(time_base)
                    .bit_rate(params.bitrate as _);

                // æ ¹æ®ä¸åŒç¼–ç å™¨è®¾ç½®ä¸åŒå‚æ•°
                match encoder_name {
                    "h264_nvenc" => {
                        // NVIDIA NVENC å‚æ•°
                        builder = builder
                            .set_option("preset", "fast") // p1-p7, fastç­‰ä»·äºp4
                            .set_option("tune", "ll") // ll = low latency, ä¸æ˜¯zerolatency
                            .set_option("profile", "high") // baseline, main, high
                            .set_option("level", "52")
                            .set_option("rc", "cbr") // ç ç‡æ§åˆ¶ï¼šcbr, vbr, cqp
                            //.set_option("cbr", "1")
                            .set_option("delay", "0") // 0å»¶è¿Ÿ
                            .set_option("zerolatency", "1") // NVENCçš„é›¶å»¶è¿Ÿæ¨¡å¼
                            .set_option("b_frames", "0") // ç¦ç”¨Bå¸§
                            .set_option("g", "60")
                            .set_option("refs", "1") // GOPå¤§å°ï¼ˆå…³é”®å¸§é—´éš”ï¼‰
                            .set_option("bufsize", "20000000") // bufsize = 20 Mbpsï¼ˆçº¦=2Ã—ç ç‡ï¼‰
                            .set_option("repeat-headers", "1"); // æ¯ä¸ªå…³é”®å¸§é‡å¤è¾“å‡º SPS/PPS
                    }
                    "h264_amf" => {
                        // AMD AMF å‚æ•°
                        builder = builder
                            .set_option("usage", "lowlatency") // ä½å»¶è¿Ÿæ¨¡å¼
                            .set_option("profile", "256")
                            .set_option("level", "auto")
                            .set_option("rc", "cbr") // æ’å®šç ç‡
                            .set_option("enforce_hrd", "1") // å¼ºåˆ¶HRDå…¼å®¹
                            .set_option("b_frames", "0") // ç¦ç”¨Bå¸§
                            .set_option("gops_per_idr", "1"); // IDRé—´éš”
                    }
                    "h264_qsv" => {
                        // Intel Quick Sync Video å‚æ•°
                        builder = builder
                            .set_option("preset", "faster") // veryfast, faster, fast, medium
                            .set_option("profile", "baseline")
                            .set_option("async_depth", "1") // å¼‚æ­¥æ·±åº¦ï¼Œ1ä¸ºæœ€ä½å»¶è¿Ÿ
                            .set_option("look_ahead", "0") // å…³é—­å‰ç»
                            .set_option("b_strategy", "0") // ç¦ç”¨Bå¸§ç­–ç•¥
                            .set_option("bf", "0") // Bå¸§æ•°é‡ä¸º0
                            .set_option("g", "30"); // GOPå¤§å°
                    }
                    "libx264" => {
                        let keyint = std::cmp::min(params.fps * 2, 60); // æœ€å¤š2ç§’ï¼Œæœ€å°‘1ç§’
                        let min_keyint = params.fps; // æœ€å°‘1ç§’ä¸€ä¸ªå…³é”®å¸§
                                                     // CPU x264 å‚æ•°ï¼ˆåŸæ¥çš„è®¾ç½®ï¼‰
                        builder = builder
                            // .set_option("preset", "ultrafast")
                            // .set_option("tune", "zerolatency")
                            // .set_option("profile", "baseline")
                            // .set_option("intra-refresh", "1")
                            // .set_option("rc-lookahead", "0")
                            // .set_option("sync-lookahead", "0")
                            // .set_option("sliced-threads", "1")
                            // .set_option("b-adapt", "0")
                            // .set_option("bframes", "0")
                            // .set_option("keyint", "30");
                            .set_option("preset", "ultrafast") // ğŸ”¥ å¿…é¡»ï¼šæœ€å¿«ç¼–ç é€Ÿåº¦
                            .set_option("tune", "zerolatency") // ğŸ”¥ å¿…é¡»ï¼šé›¶å»¶è¿Ÿè°ƒä¼˜
                            .set_option("profile", "baseline") // ğŸ”¥ å¿…é¡»ï¼šbaseline profile
                            // å¸§ç»“æ„ - æœ€ç®€å•çš„é…ç½®
                            .set_option("bframes", "0") // ğŸ”¥ å¿…é¡»ï¼šç¦ç”¨Bå¸§
                            .set_option("keyint", "25") // ğŸ”¥ å…³é”®ï¼šæ¯25å¸§ä¸€ä¸ªå…³é”®å¸§(1ç§’)
                            .set_option("min-keyint", "25") // ğŸ”¥ å…³é”®ï¼šå¼ºåˆ¶å…³é”®å¸§é—´éš”
                            // å»¶è¿Ÿæ§åˆ¶ - åªä¿ç•™æ ¸å¿ƒå‚æ•°
                            .set_option("rc-lookahead", "0") // ğŸ”¥ å¿…é¡»ï¼šç¦ç”¨å‰ç»
                            .set_option("sync-lookahead", "0") // ğŸ”¥ å¿…é¡»ï¼šç¦ç”¨åŒæ­¥å‰ç»
                            // çº¿ç¨‹å’Œåˆ‡ç‰‡ - ç®€åŒ–è®¾ç½®
                            .set_option("sliced-threads", "1") // ğŸ”¥ é‡è¦ï¼šå•çº¿ç¨‹åˆ‡ç‰‡
                            .set_option("threads", "1") // ğŸ”¥ å…³é”®ï¼šå•çº¿ç¨‹ç¼–ç ï¼Œé¿å…ç«äº‰
                    }
                    _ => {}
                }

                // å°è¯•æ„å»ºç¼–ç å™¨
                match builder.build() {
                    Ok(encoder) => {
                        println!("Successfully created {} encoder", encoder_name);
                        return Ok(encoder);
                    }
                    Err(e) => {
                        println!(
                            "Failed to create {} encoder: {}, trying next...",
                            encoder_name, e
                        );
                        continue;
                    }
                }
            }
        }

        Err(Error::new("No suitable encoder found".to_string()))
    }

    pub async fn remove_track(
        &mut self,
        client_uuid: &str,
    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let mut encoders = self.encoders.write().await;
        if let Some(worker) = encoders.remove(client_uuid) {
            worker.shutdown.store(true, Ordering::Relaxed);
            // ç­‰å¾…çº¿ç¨‹ç»“æŸ
            if let Err(e) = worker.handle.join() {
                eprintln!("Error waiting for encoder to finish: {:?}", e);
            }
        } else {
            println!("[FFMPEG]å…³é—­{:?}å¤±è´¥", client_uuid)
        }
        if encoders.is_empty() {
            drop(encoders);
            let res = self.stop_capture().await;
            println!("[FFMPEG]æ— ç¼–ç å™¨å·¥ä½œï¼Œåœæ­¢å½•å±");
            return res;
        }
        Ok(())
    }

    pub async fn stop_capture(&mut self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        // åœæ­¢æ‰€æœ‰ç¼–ç å™¨
        {
            let mut encoders = self.encoders.write().await;
            for (_, worker) in encoders.drain() {
                worker.shutdown.store(true, Ordering::Relaxed);
                // ç­‰å¾…çº¿ç¨‹ç»“æŸ
                let _ = worker.handle.join();
            }
        }

        // åœæ­¢æ•è·
        if let Some(handle) = self.capture_handle.take() {
            self.capture_shutdown.store(true, Ordering::Relaxed);
            // ç­‰å¾…çº¿ç¨‹ç»“æŸ
            let _ = handle.join();
        }

        self.frame_broadcast = None;
        Ok(())
    }
}
